# AI_GenDev

📘 **이 노트북은 데이터 분석 및 머신러닝 학습을 위한 실습 내용을 정리한 것입니다.**


# 📘1. KNN 실습 

K-최근접 이웃 알고리즘(K-Nearest Neighbors)을 다양한 데이터셋에 적용해보며  
회귀 및 분류 문제에 대한 모델 성능, 데이터 스케일링의 중요성, 예측 결과 해석 등을 실습한 자료입니다.

## 📁 파일
- 📄 [`knn_project.ipynb`](./knn_project.ipynb)  
  → KNN 알고리즘을 이용한 회귀/분류 실습, 스케일링 효과 비교, 붓꽃 분류 등 포함

## 🧪 실습 주제
- KNN 회귀 (부동산 가격 예측)
- KNN 분류 (붓꽃 아이리스 분류)
- 데이터 스케일링 전후 성능 비교
- 다양한 k 값에 따른 정확도 변화 시각화

# 📘 2. Linear, Ridge, Lasso Regression 실습 

선형 회귀(Linear Regression)와 정규화 기법인 Ridge, Lasso 모델을 이용해
연속형 타겟 변수 예측을 수행하고, **과적합 방지**, **모델 해석**, **성능 비교** 등을 실습한 자료입니다.

## 📁 파일
- 📄 [`Linear_Ridge_Lasso.ipynb`](./Linear_Ridge_Lasso.ipynb)  
  → 선형 회귀 계열 모델 적용, 성능 지표 비교, 가중치 변화 시각화, 규제 효과 분석 등 포함

## 🧪 실습 주제
- 선형 회귀 (Linear Regression)
- 릿지 회귀 (Ridge Regression, L2 규제)
- 라쏘 회귀 (Lasso Regression, L1 규제)
- 회귀 성능 지표 비교
- alpha 값 변화에 따른 가중치 변화 시각화
- 과적합 방지 효과 확인

## 💡 주요 포인트
- Ridge: 모든 피처 사용, **가중치만 줄여서 과적합 억제**
- Lasso: **불필요한 피처는 제거 (가중치 0으로)** → 변수 선택 효과
- 단순 선형 회귀보다 일반화 성능 향상

# 📘 3. 고객 이탈 예측 실습 - Decision Tree & SVM 모델 비교

고객 이탈 데이터셋을 기반으로, 의사결정트리(Decision Tree)와 서포트 벡터 머신(SVM) 모델을 활용하여  
이탈 여부를 예측하고, 두 모델의 성능을 비교 분석한 실습 자료입니다.

## 📁 파일
- 📄 [`DecisionTree_SVM_Telco_Churn_Assignment_Only.ipynb`](./DecisionTree_SVM_Telco_Churn_Assignment_Only.ipynb)  
  → 고객 이탈 데이터셋을 활용한 전처리, 의사결정트리 & SVM 모델 비교, 성능 분석 및 시각화 포함

## 🧪 실습 주제
- 고객 이탈(`Churn`)을 타겟으로 한 **이진 분류(Binary Classification) 문제**
- **의사결정트리(DecisionTreeClassifier)** 와 **SVM(Support Vector Classifier)**을 적용
- 모델 성능을 **정확도, 정밀도(Precision), 재현율(Recall), F1-score**로 비교
- 결정트리 시각화를 통한 **주요 분기 기준 해석**
- 샘플 1건에 대한 예측 결과 비교 (두 모델이 동일하게 판단하는지 확인)

## 주요 전처리 내용

- `TotalCharges` 컬럼의 문자열 → 수치형 변환 및 결측치 처리
- `Churn` 컬럼 이진화 (`Yes` → 1, `No` → 0)
- `customerID` 제거 (식별자)
- 범주형 변수 → **원-핫 인코딩** (`get_dummies`)
- `train_test_split()`을 사용하여 **학습/테스트 데이터 분할**
- 결측치 제거 (`dropna()`) 

## 학습 소감
이번 실습을 통해 모델 성능을 단순한 정확도 외에도 정밀도, 재현율 등 **다양한 평가 지표를 활용해 해석하는 경험**을 할 수 있었습니다.  
특히 의사결정트리 시각화를 통해 **모델이 어떤 기준으로 분기하고 판단하는지 직접 확인**할 수 있었고,  
**상황에 따라 어떤 모델을 선택해야 할지 고민해보는 시간**이 되었습니다.

# 📘 4. 심장병 예측 실습 - 다양한 모델 비교 및 앙상블 적용
심장병(Heart Disease) 데이터셋을 기반으로,
다양한 분류 모델(Logistic Regression, SVC, Random Forest)을 활용하여 심장병 여부를 예측하고,
앙상블 기법(Voting Classifier)을 적용하여 성능을 비교 분석한 실습 자료입니다.

## 📁 파일
📄 [`Heart_Disease_Scenario_Assignment.ipynb`](./Heart_Disease_Scenario_Assignment.ipynb)
→ 심장병 데이터 전처리, 다양한 분류 모델 적용, 앙상블 모델 실습 내용 포함

## 🧪 실습 주제
- 심장병(Heart Disease) 여부를 타겟으로 한 이진 분류(Binary Classification) 문제
- Logistic Regression, Support Vector Classifier(SVC), Random Forest 적용
- Hard Voting, Soft Voting 앙상블 기법 실습
- 각 모델의 성능을 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-score로 비교
- 샘플건에 대해 개별 모델의 예측 결과를 비교

## 주요 전처리 내용
- TotalCharges 컬럼의 공백 제거 및 수치형 변환
- Churn (or 심장병 예측시 target 변수) 이진화 (Yes → 1, No → 0)
- 필요 없는 식별자 컬럼(customerID) 제거
- 범주형 변수 → 원-핫 인코딩(pd.get_dummies)
- train_test_split()으로 학습/테스트 데이터 분리

## 학습 소감
이번 실습을 통해 환자 진단처럼 신중함이 필요한 문제에서는 단순히 정확도만 보는 것을 넘어,
상황에 맞는 모델 선택 기준을 고민하는 경험을 할 수 있었습니다.
특히 질병이 있는 환자를 놓치는 상황(False Negative)은 심각한 결과를 초래할 수 있기 때문에, 이 경우에는 재현율(Recall) 이 높은 모델을 선택하는 것이 중요하다는 점을 배웠습니다.
반대로, 질병이 없는 환자에게 고비용 치료나 불필요한 처치를 적용하는 것을 막기 위해서는 정밀도(Precision) 가 높은 모델을 선택해야 한다는 점도 함께 이해할 수 있었습니다.
또한, 단일 모델만 사용하는 것이 아니라 여러 모델의 강점을 조합한 앙상블 모델을 실습하면서,다양한 모델을 융합해 성능을 높이는 방법까지 경험해볼 수 있었습니다.
이번 실습을 통해 실제 문제 상황에서는 단일 지표나 모델에 의존하지 않고, 다양한 접근법을 유연하게 적용할 수 있어야 한다는 점을 느낄 수 있었던 시간이었습니다.

# 📘 5. 퍼셉트론과 다층 퍼셉트론 구현하기

퍼셉트론(perceptron) 모델과 다층 퍼셉트론(MLP)을 직접 구현하여 문제를 해결하고,  
활성화 함수 구현 및 가중치(weight)와 편향(bias)의 행렬 연산을 수작업으로 실습해보는 자료입니다.

## 📁 파일
📄 [`perceptron_mlp_mission.ipynb`](./perceptron_mlp_mission.ipynb)
→ 퍼셉트론(Perceptron), 다층 퍼셉트론(MLP), 활성화 함수 구현 실습 내용을 포함하고 있습니다.

## 🧪 실습 주제
- 퍼셉트론(perceptron)을 직접 코딩하여 논리 연산(AND, OR, XOR) 구현
- 다층 퍼셉트론(MLP)을 직접 구현하여 XOR 문제 해결
- 활성화 함수(sigmoid, ReLU 등) 구현
- 가중치(weight)와 편향(bias)의 행렬 연산 수작업으로 구현

## 📚 학습 소감
이번 실습을 통해 본격적으로 딥러닝을 배우기 시작하였습니다.  
처음 접하는 내용이 많아 하나의 개념을 이해하고 구현하는 데 시간이 오래 걸렸지만, 천천히 직접 구현해보면서 연산 과정과 흐름을 고민하고 이해해보는 좋은 경험이 되었습니다.
또한 은닉층 뉴런 수를 2개에서 3개 이상으로 변경해보는 실습도 진행하였는데, 단순히 뉴런 수를 늘리는 것만으로는 성능 향상이 이루어지지 않으며,  
**가중치와 편향을 어떻게 설정하느냐가 훨씬 더 중요하다는 점**을 깨닫게 되었습니다.
아직 100% 완벽하게 이해했다고 말하기는 어렵지만, 앞으로도 계속해서 구현하고 실습을 반복하면서 더 익숙해지고,  
깊이 있는 이해를 쌓아가야겠다는 생각이 들었습니다.

# 📘 6. MNIST 손글씨 숫자 인식기 직접 구현 

딥러닝의 기초 개념인 **신경망 구조**, **행렬 연산**, **활성화 함수 구현**, 그리고 **사전 학습된 가중치 파일을 활용한 추론** 과정을 통해  
MNIST 손글씨 숫자 데이터셋 분류 문제를 다루는 실습입니다.

## 📁 파일
📄 [`mnist_20250429.ipynb`](./mnist_20250429.ipynb)
→ MNIST 데이터를 활용한 순전파 신경망 추론 및 실습 내용을 포함하고 있습니다.

## 🧪 실습 주제
- `forward()` 함수 직접 구현하여 입력 데이터를 통해 출력 벡터 생성
- 이미지 벡터(784차원)를 28×28 이미지로 변환하여 시각화
- `np.argmax()`를 통해 softmax 출력 중 가장 높은 확률의 클래스를 예측값으로 반환
- 예측 결과를 `matplotlib`을 활용하여 시각적으로 표현

## 📚 학습 소감

처음에는 행렬 곱이나 활성화 함수 개념이 어렵게 느껴졌다. 하지만, 하나씩 구현하고 예제에 적용해보며 점차 이해할 수 있었다. 
예측 결과를 이미지로 직접 확인해보는 과정에서 내가 만든 모델이 동작하는 원리를 눈으로 확인할 수 있어 흥미로웠다.

# 📘 7. 3D 드론 착륙 위치 예측 신경망

드론이 위도, 경도, 고도 정보를 기반으로 실제 착륙해야 할 3차원 좌표 (X, Y, Z)를 예측하는 다층 퍼셉트론(MLP) 모델을 직접 구현하였습니다.
순전파, 역전파, 활성화 함수, 가중치 및 편향의 행렬 연산을 numpy만 사용하여 구현하였고, 학습 손실 추이를 시각화하여 딥러닝의 기초 학습 과정을 체험할 수 있도록 구성된 실습 자료입니다.

## 📁 파일
📄 [`drone_3d_multivariable_nn.ipynb`](./drone_3d_multivariable_nn.ipynb)
→ 위도/경도/고도 입력을 받아 착륙 좌표를 예측하는 MLP 신경망 구현 실습 내용을 포함하고 있습니다.

## 🧪 실습 주제
- 다층 퍼셉트론(MLP)을 직접 구현하여 3차원 좌표 예측 문제 해결
- ReLU 활성화 함수 및 미분 함수 직접 구현
- Mean Squared Error 손실 함수 구현
- 순전파(forward propagation) 및 역전파(backpropagation) 과정 코딩
- 학습률, 손실값 변화 관찰을 통해 경사하강법(Gradient Descent) 이해

## 📚 학습 소감

딥러닝 모델이 어떻게 입력을 처리하고 오차를 줄여나가는지를 처음부터 직접 구현해보며 이해할 수 있었습니다.
수식을 코드로 옮기는 과정에서 forward와 backward의 흐름을 더 명확하게 이해할 수 있었습니다.

# 📘 8. XOR 문제를 Numpy와 Pytorch로 신경망 구현

XOR 문제를 Numpy와 Pytorch 2가지 버전으로 구현해보는 실습입니다. 
순전파(forward propagation), 손실 계산(loss), 역전파(backpropagation, 연쇄 법칙 기반), 확률적 경사 하강법(SGD)을 통해 파라미터를 갱신하며, 학습률 변화에 따른 결과도 실험해봅니다.

## 📁 파일
📄[`20250501_deep_learning_school_admission_exam.ipynb`](./20250501_deep_learning_school_admission_exam.ipynb)
→ XOR문제를 2층 신경망으로 구현하고 순전파, 역전파 과정을 실습한 내용을 포함하고 있습니다. 

## 🧪 실습 주제
- forward, loss, backward를 구현해보며 딥러닝 구조 및 원리 이해
- 학습률에 변화에 따른 모델 성능 비교 실험
- 옵티마이저 종류 비교 및 개념 정리 (SGD, Momentum, RMSProp, Adam)
- 파이토치 기초 문법을 익히고, Numpy로 구현한 신경망과 비교

## 📚 학습 소감

오늘은 딥러닝의 핵심 개념 중 하나인 역전파(backpropagation)를 Numpy로 직접 구현해보았다. 저번 실습에서는 이해한 것 같있는데, 지금 다시 보니 또 막히는 그 마법.. def backward(...) 부분에서 특히 어려움을 느꼈는데, 역전파의 전체적인 흐름은 이해했지만, 각 수식이 왜 그런 방식으로 기울기를 계산하는지까지는 명확히 와닿지 않았다. 아직 수학적인 기반이 부족해서 공식의 의미를 온전히 이해하지 못한 것 같다. 이 부분에서 오래 고민하다 보니 다른 계획한 일을 진행하지 못한 것 같아, 다음 실습을 통해 조금씩 감을 잡아가야겠다고 생각했다. 지금은 이해가 완벽하지 않아도 괜찮다. 계속 구현하고 부딪히면서 결국 내 것이 될 거라 믿는다!!!!! keep going ~ 🔥

# 📘 9. MNIST 손글씨 숫자 분류기 구현 

pytorch를 활용해 MNIST 데이터셋을 분류하는 신경망을 구현하고 학습 시켰습니다.
DataLoader를 이용해 배치 단위로 데이터를 불러오고, nn.Sequential 또는 nn.Module로 모델을 구성한 뒤, 
SGD 옵티마이저와 CrossEntropyLoss를 사용해 학습을 수행하였습니다. 또한 에폭별 손실 그래프 시각화도 진행했습니다. 

## 📁 파일
📄[`20250502_dl_beginner_mission.ipynb`](./20250502_dl_beginner_mission.ipynb)
→ MNIST 데이터 셋을 기반으로 MLP 신경망을 학습 시키고, 학습 손실을 시각화 하는 내용을 담고 있습니다. 

## 🧪 실습 주제
- torchvision.datasets.MNIST를 이용한 학습/테스트 데이터 불러오기
- transforms.Compose로 이미지 정규화 및 텐서 변환
- DataLoader를 활용한 배치 구성(batch_size=64)
- nn.Sequential 및 nn.Module을 활용한 모델 정의
- 손실 함수 CrossEntropyLoss , 옵티마이저 SGD 사용
- 예측 -> 손실 계산 -> 역전파 -> 파라미터 업데이트 순으로 학습 루프 구현
- 학습 손실 곡선 시각화
- 정확도 평가 함수 구현 

## 📚 학습 소감
MNIST 숫자 분류기를 구현하면서 pytorch의 전체 흐름을 따라가 봤다. Sequential 을 경험해보니, 파이토치가 얼마나 유연하고 직관적인지 알게 되었다. 구현 도중 view(-1, 28*28)과 같이 이미지를 평탄화하지 않아 생긴 에러를 겪으면서, 딥러닝 학습 흐름에서 데이터 형태(shape)가 얼마나 중요한지 직접 체감할 수 있었다. 이전에 직접 역전파를 구현했을 때도 마찬가지로 shape을 맞추는 게 핵심이었는데, 아직은 텐서 형태를 직관적으로 바라보는 눈이 부족하다는 것도 느꼈다. 현재는 코드를 처음부터 혼자 짜기보다는, 강사님의 설명을 따라치고 구조를 이해하는 단계지만, 하나하나 “왜 이렇게 작성되는 걸까?”를 질문하고, 그 결과를 직접 눈으로 확인해보는 과정을 통해 이해의 깊이가 점점 쌓이고 있다는 느낌을 받는다. 앞으로는 조금씩 더 직접 구현해보는 방식으로 학습을 확장해보고 싶다.

# 📘 10. 맛집 리뷰 분석 

[연세대학교 DSL 자연어처리 실습 자료](https://github.com/DataScience-Lab-Yonsei/24-1_DSL_Modeling_NLP2_Restaurant_Review_Sentiment_Analysis) 를 참고하여 한식 맛집 리뷰 데이터를 기반으로 konlpy의 Okt 형태소 분석기를 활용하여 자주 나오는 키워드를 추출하고 시각화했습니다.
식당별로 키워드 빈도를 비교하여 각 장소의 특징적인 표현을 분석합니다.

## 🔗 참고 자료
- [연세대학교 DSL 자연어처리 실습 자료](https://github.com/DataScience-Lab-Yonsei/24-1_DSL_Modeling_NLP2_Restaurant_Review_Sentiment_Analysis)


## 📁 파일
📄['NLP_Mission_GitHub_Dataset.ipynb'](./NLP_Mission_GitHub_Dataset.ipynb)
→ 형태소 분석부터 시각화 실습 내용을 포함하고 있습니다. 

## 🧪 실습 주제
- pandas로 데이터셋 로드 및 전처리 
- konlpy의 Okt를 이용하여 형태소 분석 (명사 추출)
- 단어 빈도 계산 및 상위 키워드 선정
- 워드 클라우드 시각화
- 식당별 키워드 빈도 비교 (막대 그래프)

## 📚 학습 소감
형태소 분석기를 활용해 리뷰 텍스트에서 키워드를 추출해보는 것은 처음이었지만, 자연어 처리의 기본 흐름을 실습을 통해 직접 경험해볼 수 있어 유익했다.
단어 빈도를 분석하고 시각화로 표현하는 과정이 흥미로웠다. 앞으로 분석 프로젝트를 진행할 때 이러한 기법들을 적용해볼 수 있다는 생각에 기대가 된다.




